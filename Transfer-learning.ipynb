{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importowanie modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import models, transforms, datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zbiory danych, modele, metody TL, hiperparametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\n",
    "    'CIFAR10'\n",
    "]\n",
    "MODELS = [\n",
    "    models.alexnet(pretrained=True),\n",
    "    #models.vgg16(pretrained=True),\n",
    "    #models.resnet50(pretrained=True)\n",
    "]\n",
    "TL_METHODS = [\n",
    "    #'no_freezing',\n",
    "    #'classic_tl',\n",
    "    'fine_tuning'\n",
    "]\n",
    "\n",
    "# Hyperparmeters\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utworzenie Data setów i data loaderów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets_and_dataloaders(dataset_name: str, model):\n",
    "\n",
    "    if isinstance(model, models.AlexNet) or isinstance(model, models.VGG) or isinstance(model, models.ResNet):\n",
    "        base_transforms = [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]\n",
    "    else:\n",
    "        base_transforms = [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]\n",
    "\n",
    "    train_transform = transforms.Compose(base_transforms)\n",
    "    test_transform = transforms.Compose(base_transforms)\n",
    "\n",
    "    preprocessing = [\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)\n",
    "    ]\n",
    "\n",
    "    train_transform.transforms.extend(preprocessing)\n",
    "\n",
    "    if dataset_name == 'CIFAR10':\n",
    "        train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "        train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "        test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "        test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        print(\"Loaders created\")\n",
    "\n",
    "    return train_set, test_set, train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przetwarzanie modeli do transfer learningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transfer_learning(model, tl_method):\n",
    "    if tl_method == 'classic_tl' or tl_method == 'fine_tuning':\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        if isinstance(model, models.AlexNet) or isinstance(model, models.VGG):\n",
    "            for param in model.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif isinstance(model, models.ResNet):\n",
    "            for param in model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    elif tl_method == 'no_freezing':\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "def customize_model(model, num_classes, tl_method):\n",
    "    if isinstance(model, models.AlexNet):\n",
    "        dropout = 0.5\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    elif isinstance(model, models.VGG):\n",
    "        dropout = 0.5\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    elif isinstance(model, models.ResNet):\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    print(\"Classifier for model has been changed.\")\n",
    "    apply_transfer_learning(model, tl_method)\n",
    "    print(\"Transfer learning method:\", tl_method, \"applied.\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja mrożąca do naszej metody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def freeze_percentage(model, percentage):\n",
    "    \"\"\"Freeze a percentage of the model's parameters based on gradient norms.\"\"\"\n",
    "    grad_params = [(param.grad.norm(), param) for param in model.parameters() if param.requires_grad and param.grad is not None]\n",
    "    grad_params.sort(key=lambda x: x[0])\n",
    "    num_params_to_freeze = int(percentage * len(grad_params))\n",
    "\n",
    "    for _, param in grad_params[:num_params_to_freeze]:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ustawienia fine-tuningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_fine_tuning(model, optimizer):\n",
    "    \"\"\"Adjust the model and optimizer for fine-tuning.\"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pętla treningowo walidacyjna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "Using the CIFAR10 dataset.\n",
      "Using the fine_tuning method\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loaders created\n",
      "Using the AlexNet model\n",
      "Classifier for model has been changed.\n",
      "Transfer learning method: fine_tuning applied.\n",
      "Training starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  15%|█▌        | 120/782 [04:43<26:06,  2.37s/it, loss=1.8] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 101\u001b[0m\n\u001b[0;32m     98\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining starts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 101\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl_method\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_loader, test_loader, criterion, optimizer, epochs, tl_method)\u001b[0m\n\u001b[0;32m     19\u001b[0m correct_train, total_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tepoch:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tepoch:\n\u001b[0;32m     23\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torchvision\\transforms\\transforms.py:1241\u001b[0m, in \u001b[0;36mColorJitter.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madjust_saturation(img, saturation_factor)\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m fn_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hue_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1241\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_hue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torchvision\\transforms\\functional.py:904\u001b[0m, in \u001b[0;36madjust_hue\u001b[1;34m(img, hue_factor)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39madjust_hue(img, hue_factor)\n\u001b[1;32m--> 904\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_hue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_factor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:209\u001b[0m, in \u001b[0;36madjust_hue\u001b[1;34m(img, hue_factor)\u001b[0m\n\u001b[0;32m    207\u001b[0m h \u001b[38;5;241m=\u001b[39m (h \u001b[38;5;241m+\u001b[39m hue_factor) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    208\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack((h, s, v), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 209\u001b[0m img_hue_adj \u001b[38;5;241m=\u001b[39m \u001b[43m_hsv2rgb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orig_dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39muint8:\n\u001b[0;32m    212\u001b[0m     img_hue_adj \u001b[38;5;241m=\u001b[39m (img_hue_adj \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255.0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39morig_dtype)\n",
      "File \u001b[1;32mc:\\Users\\rafal\\.conda\\envs\\deeplearning\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:312\u001b[0m, in \u001b[0;36m_hsv2rgb\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m    310\u001b[0m a2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack((t, v, v, q, p, p), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    311\u001b[0m a3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack((p, p, t, v, v, q), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 312\u001b[0m a4 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...ijk, ...xijk -> ...xjk\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mdtype), a4)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using: {device}\")\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs, tl_method):\n",
    "    \"\"\"Train and evaluate the model.\"\"\"\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'val_accuracy': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch + 1}\") as tepoch:\n",
    "            for images, labels in tepoch:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "                \n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        val_loss, val_accuracy = evaluate_model(model, test_loader, criterion, running_loss, tl_method, optimizer)\n",
    "\n",
    "        history['train_loss'].append(running_loss / len(train_loader))\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "    if tl_method == 'fine_tuning':\n",
    "        adjust_fine_tuning(model, optimizer)\n",
    "        print(\"Fine tuning applied. Learning rate: \", optimizer.lr)\n",
    "        tl_method = 'no_freezing'\n",
    "        fine_tuning_history = train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs, tl_method)\n",
    "        history = {key: history[key] + fine_tuning_history[key] for key in history}\n",
    "\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, running_loss):\n",
    "    \"\"\"Evaluate the model and adjust learning rate if fine-tuning.\"\"\"\n",
    "    model.eval()\n",
    "    val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "    print(f'Train Loss: {running_loss/len(train_loader)}, '\n",
    "          f'Validation Loss: {val_loss/len(test_loader)}, '\n",
    "          f'Accuracy: {100 * correct_val / total_val}%')\n",
    "    \n",
    "    return avg_val_loss, val_accuracy\n",
    "\n",
    "\n",
    "# Main loop\n",
    "for id_dataset, dataset in enumerate(DATASETS):\n",
    "    print(f\"Using the {dataset} dataset.\")\n",
    "    \n",
    "\n",
    "    for id_tl_method, tl_method in enumerate(TL_METHODS):\n",
    "        print(f\"Using the {tl_method} method\")\n",
    "\n",
    "        for id_model, model in enumerate(MODELS):\n",
    "            train_set, test_set, train_loader, test_loader = create_datasets_and_dataloaders(dataset, model=model)\n",
    "            num_classes = len(train_set.classes)\n",
    "\n",
    "            print(f\"Using the {model.__class__.__name__} model\")\n",
    "            model = customize_model(model, num_classes, tl_method)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            model.to(device)\n",
    "\n",
    "            print(\"Training starts\")\n",
    "            train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, EPOCHS, tl_method)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
